{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d1ba2a2-dace-4697-ada3-c1cd955ddf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c14501ea-4f36-4195-9d2f-af75de9e5513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "td=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "train_data=td.flow_from_directory('dataset/training_set',batch_size=32,target_size=(64,64,),class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7e7187b-f984-4b3d-b071-68fe72d5ebda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1992 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "ts=ImageDataGenerator(rescale=1./255)\n",
    "test_data=td.flow_from_directory('dataset/test_set',batch_size=32,class_mode='binary',target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b6180fe-9774-43cd-8423-c430cfb91b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k.navadeepreddy\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D,MaxPool2D,Flatten,Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "model=Sequential()\n",
    "model.add(Conv2D(filters=32,kernel_size=3,input_shape=[64,64,3],activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2,strides=2,padding='same'))\n",
    "model.add(Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2,strides=2,padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f32ca104-0863-4d2f-9ff8-cd066298032f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 362ms/step - accuracy: 0.5429 - loss: 0.6850 - val_accuracy: 0.6391 - val_loss: 0.6319\n",
      "Epoch 2/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 92ms/step - accuracy: 0.6710 - loss: 0.6105 - val_accuracy: 0.6973 - val_loss: 0.5801\n",
      "Epoch 3/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 96ms/step - accuracy: 0.7056 - loss: 0.5642 - val_accuracy: 0.7480 - val_loss: 0.5360\n",
      "Epoch 4/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 92ms/step - accuracy: 0.7355 - loss: 0.5222 - val_accuracy: 0.7304 - val_loss: 0.5327\n",
      "Epoch 5/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 94ms/step - accuracy: 0.7627 - loss: 0.4866 - val_accuracy: 0.7239 - val_loss: 0.5526\n",
      "Epoch 6/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 96ms/step - accuracy: 0.7704 - loss: 0.4729 - val_accuracy: 0.7620 - val_loss: 0.4922\n",
      "Epoch 7/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 93ms/step - accuracy: 0.7804 - loss: 0.4577 - val_accuracy: 0.7580 - val_loss: 0.4908\n",
      "Epoch 8/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 99ms/step - accuracy: 0.7830 - loss: 0.4592 - val_accuracy: 0.7686 - val_loss: 0.4853\n",
      "Epoch 9/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 97ms/step - accuracy: 0.7978 - loss: 0.4345 - val_accuracy: 0.7761 - val_loss: 0.4845\n",
      "Epoch 10/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 97ms/step - accuracy: 0.7983 - loss: 0.4276 - val_accuracy: 0.7821 - val_loss: 0.4706\n",
      "Epoch 11/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 96ms/step - accuracy: 0.8035 - loss: 0.4234 - val_accuracy: 0.7806 - val_loss: 0.4700\n",
      "Epoch 12/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 96ms/step - accuracy: 0.8170 - loss: 0.3998 - val_accuracy: 0.7756 - val_loss: 0.4884\n",
      "Epoch 13/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 100ms/step - accuracy: 0.8356 - loss: 0.3747 - val_accuracy: 0.7917 - val_loss: 0.4538\n",
      "Epoch 14/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 96ms/step - accuracy: 0.8342 - loss: 0.3665 - val_accuracy: 0.7831 - val_loss: 0.4847\n",
      "Epoch 15/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 95ms/step - accuracy: 0.8448 - loss: 0.3463 - val_accuracy: 0.8062 - val_loss: 0.4580\n",
      "Epoch 16/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 95ms/step - accuracy: 0.8501 - loss: 0.3339 - val_accuracy: 0.7887 - val_loss: 0.4606\n",
      "Epoch 17/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 98ms/step - accuracy: 0.8527 - loss: 0.3350 - val_accuracy: 0.7897 - val_loss: 0.4721\n",
      "Epoch 18/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 97ms/step - accuracy: 0.8513 - loss: 0.3236 - val_accuracy: 0.7957 - val_loss: 0.4700\n",
      "Epoch 19/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 95ms/step - accuracy: 0.8658 - loss: 0.3119 - val_accuracy: 0.7972 - val_loss: 0.4761\n",
      "Epoch 20/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 95ms/step - accuracy: 0.8772 - loss: 0.2942 - val_accuracy: 0.7962 - val_loss: 0.4739\n",
      "Epoch 21/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 96ms/step - accuracy: 0.8808 - loss: 0.2846 - val_accuracy: 0.8062 - val_loss: 0.4458\n",
      "Epoch 22/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 95ms/step - accuracy: 0.8828 - loss: 0.2691 - val_accuracy: 0.8082 - val_loss: 0.4777\n",
      "Epoch 23/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 96ms/step - accuracy: 0.8956 - loss: 0.2517 - val_accuracy: 0.8017 - val_loss: 0.4876\n",
      "Epoch 24/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 94ms/step - accuracy: 0.8969 - loss: 0.2524 - val_accuracy: 0.8112 - val_loss: 0.4651\n",
      "Epoch 25/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 99ms/step - accuracy: 0.8967 - loss: 0.2395 - val_accuracy: 0.7972 - val_loss: 0.5139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x26ecb8ed2e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(train_data,validation_data=test_data,epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23f0704b-f3d4-4feb-b80a-142828b56054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Image1:Dog\n",
      "Image2:Cat\n",
      "Image3:Cat\n",
      "Image4:Dog\n",
      "Image5:Dog\n",
      "Image6:Cat\n",
      "Image7:Dog\n",
      "Image8:Dog\n",
      "Image9:Dog\n",
      "Image10:Dog\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing import image\n",
    "images='dataset/single_prediction'\n",
    "images_path=[os.path.join(images,fname) for fname in os.listdir(images)]\n",
    "img=[]\n",
    "for imgs in images_path:\n",
    "    test_data_set=image.load_img(imgs,target_size=(64,64))\n",
    "    test_data_set=image.img_to_array(test_data_set)\n",
    "    test_data_set=np.expand_dims(test_data_set,axis=0)\n",
    "    img.append(test_data_set)\n",
    "pre=np.vstack(img)\n",
    "pred=model.predict(pre)\n",
    "for i,res in enumerate(pred):\n",
    "    pre_label='Dog' if res[0]>0.5 else 'Cat'\n",
    "    print(f\"Image{i+1}:{pre_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351844fc-3e60-497c-b06e-dde8df28302f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
